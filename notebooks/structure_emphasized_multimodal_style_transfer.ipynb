{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ud24EThsJ5Nh"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DQv5KY_LLaf5",
    "outputId": "a2867670-47aa-4343-af7a-2ec14af806f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /home/shaorrran/.virtualenvs/dls/lib/python3.8/site-packages (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eOhvtnD5J49-"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import glob\n",
    "import io\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "\n",
    "import skimage\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a20tbSYkLmHc"
   },
   "source": [
    "# Setting random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mxq29ZwVLqJz"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "random.seed(RANDOM_STATE)\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") != \"\" and os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") is not None:\n",
    "    RUNNER = \"kaggle\"\n",
    "elif \"google.colab\" in str(IPython.get_ipython()):\n",
    "    RUNNER = \"colab\"\n",
    "else:\n",
    "    # assume running on a local machine\n",
    "    RUNNER = \"local\"\n",
    "print(RUNNER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aWsRicMMXxH"
   },
   "source": [
    "# Determining device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XtZOpwh-MZvB",
    "outputId": "2b14ded5-ee51-44de-c5a1-4f544842cd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K--tlf-bNvPJ"
   },
   "source": [
    "# Setting globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "moKn5k7UOBsg"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "IMAGE_SIZE = 128\n",
    "NORMALIZATION_PARAMS = {\"mean\": (0.485, 0.456, 0.406),\n",
    "                        \"std\": (0.229, 0.224, 0.225)}\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)\n",
    "USE_SMALLER_DATASET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCHZO0NlS9kS"
   },
   "source": [
    "# Helper functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "brHE-1DxTIlg"
   },
   "outputs": [],
   "source": [
    "class Denormalize():\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        for t, m ,s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "class StyleTransferDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, content_dir, style_dir, transforms=None):\n",
    "        content_images = glob.glob(content_dir + \"/*\")\n",
    "        style_images = glob.glob(style_dir + \"/*\")\n",
    "        self.images = list(zip(content_images, style_images))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content, style = self.images[idx]\n",
    "        content_img = skimage.io.imread(content)\n",
    "        if len(content_img.shape) < 3:\n",
    "            content_img = skimage.color.gray2rgb(content_img)\n",
    "        style_img = skimage.io.imread(style)\n",
    "        if len(style_img.shape) < 3:\n",
    "            content_img = skimage.color.gray2rgb(content_img)\n",
    "        content_img = torchvision.transforms.ToTensor()(content_img)\n",
    "        style_img = torchvision.transforms.ToTensor()(style_img)\n",
    "        if self.transforms:\n",
    "            content_img, style_img = self.transforms(content_img), self.transforms(style_img)\n",
    "        return content_img, style_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pm0u7GMPXpbq"
   },
   "outputs": [],
   "source": [
    "class AdaptiveInstanceNorm2d(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def _get_mean(self, features):\n",
    "        batch_size, c = features.size()[:2]\n",
    "        features_mean = features.reshape(batch_size, c, -1).mean(dim=2).reshape(batch_size, c, 1, 1)\n",
    "        return features_mean\n",
    "    \n",
    "    def _get_std(self, features):\n",
    "        batch_size, c = features.size()[:2]\n",
    "        features_std = features.reshape(batch_size, c, -1).std(dim=2).reshape(batch_size, c, 1, 1) + self.eps\n",
    "        return features_std\n",
    "\n",
    "    def forward(self, content, style):\n",
    "        content_mean, content_std = self._get_mean(content), self._get_std(content)\n",
    "        style_mean, style_std = self._get_mean(style), self._get_std(style)\n",
    "        normalized = style_std * (content - content_mean) / content_std + style_mean\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_gdrive(id, dest):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "    session = requests.Session()\n",
    "    response = session.get(URL, params={\"id\": id}, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "    if token:\n",
    "        params = {\"id\": id, \"confirm\": token}\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    save_response_content(response, dest)\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for k, v in response.cookies.items():\n",
    "        if k.startswith(\"download_warning\"):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, dest):\n",
    "    with open(dest, \"wb\") as f:\n",
    "        for chunk in tqdm.tqdm(response.iter_content(32768), desc=\"Downloading file\", unit=\"chunks\", unit_scale=False):\n",
    "            if chunk:\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters, device=\"cpu\", tol=1e-4, init=\"kmeans++\"):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.device = device\n",
    "        self.tol = tol\n",
    "        self.init = init\n",
    "        self._labels = None\n",
    "        self._cluster_centers = None\n",
    "\n",
    "    def _initial_state(self, data):\n",
    "        if self.init == \"kmeans++\":\n",
    "            n, c = data.shape\n",
    "            dis = torch.zeros((n, self.n_clusters), device=self.device)\n",
    "            initial_state = torch.zeros((self.n_clusters, c), device=self.device)\n",
    "            pr = np.repeat(1 / n, n)\n",
    "            initial_state[0, :] = data[np.random.choice(np.arange(n), p=pr)]\n",
    "            dis[:, 0] = torch.sum((data - initial_state[0, :]) ** 2, dim=1)\n",
    "\n",
    "            for k in range(1, self.n_clusters):\n",
    "                pr = torch.sum(dis, dim=1) / torch.sum(dis)\n",
    "                try:\n",
    "                    initial_state[k, :] = data[np.random.choice(np.arange(n), 1, p=pr.cpu().numpy())]\n",
    "                except Exception:\n",
    "                    initial_state[k, :] = data[np.random.choice(np.arange(n), 1, p=np.flatten(np.random.default_rng().dirichlet(np.ones(len(pr)), size=1)))]\n",
    "                dis[:, k] = torch.sum((data - initial_state[k, :]) ** 2, dim=1)\n",
    "        else:\n",
    "            n = data.shape[0]\n",
    "            indices = np.random.choice(n, self.n_clusters)\n",
    "            initial_state = data[indices]\n",
    "\n",
    "        return initial_state\n",
    "\n",
    "    @staticmethod\n",
    "    def pairwise_distance(data1, data2=None):\n",
    "        if data2 is None:\n",
    "            data2 = data1\n",
    "\n",
    "        a = data1.unsqueeze(dim=1)\n",
    "        b = data2.unsqueeze(dim=0)\n",
    "\n",
    "        dis = (a - b) ** 2.0\n",
    "        dis = dis.sum(dim=-1).squeeze()\n",
    "        return dis\n",
    "    \n",
    "    def fit(self, data):\n",
    "        data = data.to(torch.float32)\n",
    "        cluster_centers = self._initial_state(data)\n",
    "\n",
    "        while True:\n",
    "            dis = self.pairwise_distance(data, cluster_centers)\n",
    "            labels = torch.argmin(dis, dim=1)\n",
    "            cluster_centers_pre = cluster_centers.clone()\n",
    "\n",
    "            for index in range(self.n_clusters):\n",
    "                selected = (labels == index)\n",
    "                if selected.any():\n",
    "                    selected = data[labels == index]\n",
    "                    cluster_centers[index] = selected.mean(dim=0)\n",
    "                else:\n",
    "                    cluster_centers[index] = torch.zeros_like(cluster_centers[0], device=self.device)\n",
    "            \n",
    "            center_shift = torch.sum(torch.sqrt(torch.sum((cluster_centers - cluster_centers_pre) ** 2, dim=1)))\n",
    "            if center_shift ** 2 < self.tol:\n",
    "                break\n",
    "        \n",
    "        self._labels = labels\n",
    "        self._cluster_centers = cluster_centers\n",
    "\n",
    "    @property\n",
    "    def labels_(self):\n",
    "        return self._labels\n",
    "    \n",
    "    @property\n",
    "    def cluster_centers_(self):\n",
    "        return self._cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5-Af7Ln7bn_K"
   },
   "outputs": [],
   "source": [
    "def fit_epoch(data_train, model, optimizer, criterion, epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    processed_data = 0\n",
    "    styled = []\n",
    "    for content, style in tqdm.tqdm(data_train, desc=f\"Fitting epoch {epoch + 1}/{epochs}\", unit=\"batch\", unit_scale=False):\n",
    "        try:\n",
    "            content, style = content.to(DEVICE), style.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output, output_features, content_features, output_middle, style_middle = model(content, style)\n",
    "            loss = criterion(output_features, content_features, output_middle, style_middle)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * content.size(0)\n",
    "            processed_data += content.size(0)\n",
    "            styled.append(output.detach().cpu())\n",
    "        finally:\n",
    "            content, style = content.cpu(), style.cpu()\n",
    "            del content, style\n",
    "            torch.cuda.empty_cache()\n",
    "    train_loss = running_loss / processed_data\n",
    "    return torch.cat(styled, dim=0), train_loss\n",
    "\n",
    "def eval_epoch(data_val, model, optimizer, criterion, epoch, epochs):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    processed_data = 0\n",
    "    styled = []\n",
    "    for content, style in tqdm.tqdm(data_val, desc=f\"Validating epoch {epoch + 1}/{epochs}\", unit=\"batch\", unit_scale=False):\n",
    "        try:\n",
    "            content, style = content.to(DEVICE), style.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                output, output_feats, content_feats, output_middle, style_middle = model(content, style)\n",
    "                loss = criterion(output_feats, content_feats, output_middle, style_middle)\n",
    "            running_loss += loss.item() * content.size(0)\n",
    "            processed_data += content.size(0)\n",
    "            styled.append(output.detach().cpu())\n",
    "        finally:\n",
    "            content, style = content.cpu(), style.cpu()\n",
    "            del content, style\n",
    "            torch.cuda.empty_cache()\n",
    "    val_loss = running_loss / processed_data\n",
    "    return torch.cat(styled, dim=0), val_loss\n",
    "\n",
    "def train_model(data_train, data_val, model, optimizer, criterion, epochs, start_epoch=0, checkpoint_cooldown=10):\n",
    "    history = []\n",
    "    prev_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    start_time = time.time()\n",
    "    with tqdm.tqdm(desc=\"Epoch\", total=epochs, unit=\"epoch\", unit_scale=False) as pbar:\n",
    "        for epoch in range(epochs):\n",
    "            try:\n",
    "                _, train_loss = fit_epoch(data_train, model, optimizer, criterion, epoch, epochs)\n",
    "                output, val_loss = eval_epoch(data_val, model, optimizer, criterion, epoch, epochs)\n",
    "                IPython.display.clear_output(wait=True)\n",
    "                history.append((train_loss, val_loss, optimizer.param_groups[0][\"lr\"]))\n",
    "                show_pics_train(data_val, output, history[-1], epoch, 6)\n",
    "                pbar.update(1)\n",
    "                pbar.refresh()\n",
    "\n",
    "                if (epoch + 1) % checkpoint_cooldown == 0:\n",
    "                    save_model(f\"nst_model_{epoch + 1}.tar\", mode=\"training\", model=model, optimizer=optimizer, loss=criterion, history=history, epoch=epoch)\n",
    "            except KeyboardInterrupt as stop:\n",
    "                tqdm.tqdm.write(f\"Training interrupted at epoch {epoch + 1}. Returning history\")\n",
    "                return history\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    tqdm.tqdm.write(f\"Overall training time: {train_time: 0.1f} seconds\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rdct7WZbdCki"
   },
   "outputs": [],
   "source": [
    "def show_pics_train(data_val, output, stats, epoch, sample_size):\n",
    "    log_template = \"Styled images on epoch {ep: 03d}.\\n\\\n",
    "    Train loss: {t_loss: 0.4f}, validation loss: {v_loss: 0.4f}\"\n",
    "    content, style = next(iter(data_val))\n",
    "    content = content[:sample_size]\n",
    "    style = style[:sample_size]\n",
    "    denorm = Denormalize(mean=NORMALIZATION_PARAMS[\"mean\"], std=NORMALIZATION_PARAMS[\"std\"])\n",
    "    styled = denorm(output[:sample_size]).permute(0, 2, 3, 1)\n",
    "    content = denorm(content).permute(0, 2, 3, 1)\n",
    "    style = denorm(style).permute(0, 2, 3, 1)\n",
    "    for i in range(sample_size):\n",
    "        plt.subplot(3, sample_size, i + 1)\n",
    "        plt.imshow(np.clip(content[i].squeeze().numpy(), 0, 1))\n",
    "        plt.title(\"Content\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(3, sample_size, i + 1 + sample_size)\n",
    "        plt.imshow(np.clip(style[i].squeeze().numpy(), 0, 1))\n",
    "        plt.title(\"Style\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(3, sample_size, i + 1 + 2 * sample_size)\n",
    "        plt.imshow(np.clip(styled[i].squeeze().numpy(), 0, 1))\n",
    "        plt.title(\"Styled\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(log_template.format(ep=epoch + 1, t_loss=stats[0], v_loss=stats[1]))\n",
    "    plt.show()\n",
    "\n",
    "def plot_pics(pics, sample_size=6):\n",
    "    for i in range(sample_size):\n",
    "        plt.subplot(2, sample_size // 2 + 1, i + 1)\n",
    "        image = pics[i]\n",
    "        image = image.permute(1, 2, 0)\n",
    "        plt.imshow(image.squeeze().numpy())\n",
    "        plt.title(\"Images\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    train_loss, val_loss, _ = zip(*history)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.plot(train_loss, label=\"Train loss\")\n",
    "    plt.plot(val_loss, label=\"Validation loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_learn_rate(history):\n",
    "    _, _, learn_rate = zip(*history)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plt.plot(learn_rate, label=\"Learn rate\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Learn rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P6GU1rxaxFtU"
   },
   "outputs": [],
   "source": [
    "def style_transfer(model, content, style):\n",
    "    model.eval()\n",
    "    try:\n",
    "        content, style = content.to(DEVICE), style.to(DEVICE)\n",
    "        if content.dim() != 4:\n",
    "            content = content.unsqueeze(0)\n",
    "        if style.dim() != 4:\n",
    "            style = style.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            styled = model.generate(content, style)\n",
    "        styled = styled.detach().cpu()\n",
    "    finally:\n",
    "        content, style = content.cpu(), style.cpu()\n",
    "        del content, style\n",
    "        torch.cuda.empty_cache()\n",
    "    return styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BW1LsS03xp-s"
   },
   "outputs": [],
   "source": [
    "def save_model(path, model, mode=\"inference\", **kwargs):\n",
    "    if mode == \"training\":\n",
    "        torch.save({\n",
    "            \"epoch\": kwargs[\"epoch\"],\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": kwargs[\"optimizer\"].state_dict(),\n",
    "            \"loss\": kwargs[\"loss\"],\n",
    "            \"history\": kwargs[\"history\"]},\n",
    "            path)\n",
    "    elif mode == \"torchscript\":\n",
    "        torch.jit.script(model).save(path)\n",
    "    else:\n",
    "        torch.save(model, path)\n",
    "\n",
    "def load_model(path, model_arch=None, mode=\"inference\", optim_class=None, optim_kwargs=None):\n",
    "    if mode == \"training\":\n",
    "        if not optim_class:\n",
    "            raise ValueError(\"Optimizer class required to load a model saved for training.\")\n",
    "        if not model_arch:\n",
    "            raise ValueError(\"Model architecture required to load a model saved for training.\")\n",
    "        model = model_arch()\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        if not optim_kwargs:\n",
    "            optim = optim_class(model.parameters())\n",
    "        else:\n",
    "            optim = optim_class(model.parameters(), **optim_kwargs)\n",
    "        optim.load_state_dict(checkpoint[\"optim_state_dict\"])\n",
    "        epoch = checkpoint[\"epoch\"]\n",
    "        loss = checkpoint[\"loss\"]\n",
    "        history = checkpoint[\"history\"]\n",
    "        model.eval()\n",
    "        return model, optim, epoch, loss, history\n",
    "    elif mode == \"torchscript\":\n",
    "        model = torch.jit.load(path)\n",
    "        model.eval()\n",
    "        return model\n",
    "    else:\n",
    "        model = torch.load(path)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "def save_history(path, history):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "\n",
    "def load_history(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okbAd8vi0d0y"
   },
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to download required data depending on runner type, and different requirements for those to work.\n",
    "\n",
    "If you are:\n",
    "* Running the notebook in a Kaggle session: add the `shaorrran/coco-wikiart-nst-dataset-512-100000` dataset to the session.\n",
    "* Running the notebook in Google Colab: upload your `kaggle.json` file into the session.\n",
    "* Running the notebook locally: have Kaggle API installed and your token ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"shaorrran/cocowikiart-nst-dataset-small\" if USE_SMALLER_DATASET \\\n",
    "else \"shaorrran/coco-wikiart-nst-dataset-512-100000\"\n",
    "if RUNNER == \"kaggle\":\n",
    "    name = DATASET_NAME.split(\"/\")[1]\n",
    "    DATASET_PATH = f\"/kaggle/input/{name}\"\n",
    "elif RUNNER == \"colab\":\n",
    "    from google.colab import files\n",
    "    files.upload()\n",
    "    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "    !mv kaggle.json /root/.kaggle/kaggle.json\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "    !kaggle datasets download -d {DATASET_NAME} --unzip\n",
    "    DATASET_PATH = os.getcwd()\n",
    "else:\n",
    "    if not (os.path.exists(\"content.zip\") and os.exists(\"style.zip\")) \\\n",
    "    and not (os.path.isdir(\"content\") and os.path.isdir(\"style\")):\n",
    "        !kaggle datasets download -d {DATASET_NAME} --unzip\n",
    "    else:\n",
    "        if os.path.exists(\"content.zip\"):\n",
    "            with zipfile.ZipFile(\"content.zip\", \"r\") as archive:\n",
    "                for member in tqdm.tqdm(archive.namelist(), desc=\"Extracting\", unit=\"files\", unit_scale=False):\n",
    "                    archive.extract(member, os.getcwd())\n",
    "            !rm content.zip\n",
    "        if os.path.exists(\"style.zip\"):\n",
    "            with zipfile.ZipFile(\"style.zip\", \"r\") as archive:\n",
    "                for member in tqdm.tqdm(archive.namelist(), desc=\"Extracting\", unit=\"files\", unit_scale=False):\n",
    "                    archive.extract(member, os.getcwd())\n",
    "            !rm style.zip\n",
    "        if not (os.path.isdir(\"content\") and os.path.isdir(\"style\")):\n",
    "                raise ValueError(\"Dataset not found.\")\n",
    "    DATASET_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6rcgpQjGLAV"
   },
   "source": [
    "# Creating Dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "VAYtGJ6IGKCG"
   },
   "outputs": [],
   "source": [
    "data = StyleTransferDataset(os.path.join(DATASET_PATH, \"content\"), os.path.join(DATASET_PATH, \"style\"))\n",
    "data_train, data_val = torch.utils.data.random_split(data, \n",
    "                                                     [int(0.95 * len(data)), len(data) - int(0.95 * len(data))], \n",
    "                                                     generator=torch.Generator().manual_seed(RANDOM_STATE))\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=int(BATCH_SIZE), shuffle=True, \n",
    "                                           num_workers=torch.multiprocessing.cpu_count(), \n",
    "                                           pin_memory=True, \n",
    "                                           drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(data_val, batch_size=int(BATCH_SIZE), shuffle=False, \n",
    "                                           num_workers=torch.multiprocessing.cpu_count(), \n",
    "                                           pin_memory=True, \n",
    "                                           drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kBHl_xKIMqs"
   },
   "source": [
    "# Defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VlbOZCbrIN7N"
   },
   "outputs": [],
   "source": [
    "class NormalizedVGG(torch.nn.Module):\n",
    "    def __init__(self, pretrained_path=None):\n",
    "        super().__init__()\n",
    "        self.tail = torch.nn.Sequential(collections.OrderedDict([\n",
    "            (\"conv_initial\", torch.nn.Conv2d(3, 3, kernel_size=1)),\n",
    "            (\"reflectpad_tail\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_tail\", torch.nn.Conv2d(3, 64, kernel_size=3)),\n",
    "            (\"act_tail\", torch.nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "        self.lower_spine = torch.nn.Sequential(collections.OrderedDict([\n",
    "            (\"reflectpad_lspine0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_lspine0\", torch.nn.Conv2d(64, 64, kernel_size=3)),\n",
    "            (\"act_lspine0\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"maxpool_lspine\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n",
    "            (\"reflectpad_lspine1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_lspine1\", torch.nn.Conv2d(64, 128, kernel_size=3)),\n",
    "            (\"act_lspine1\", torch.nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "        self.spine = torch.nn.Sequential(collections.OrderedDict([\n",
    "            (\"reflectpad_spine0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_spine0\", torch.nn.Conv2d(128, 128, kernel_size=3)),\n",
    "            (\"act_spine0\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"maxpool_spine\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n",
    "            (\"reflectpad_spine1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_spine1\", torch.nn.Conv2d(128, 256, kernel_size=3)),\n",
    "            (\"act_spine1\", torch.nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "        self.neck = torch.nn.Sequential(collections.OrderedDict([\n",
    "            (\"reflectpad_neck0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_neck0\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act_neck0\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad_neck1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_neck1\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act_neck1\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad_neck2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_neck2\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act_neck2\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"maxpool_neck\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n",
    "            (\"reflectpad_neck3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_neck3\", torch.nn.Conv2d(256, 512, kernel_size=3)),\n",
    "            (\"act_neck3\", torch.nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "        self.head = torch.nn.Sequential(collections.OrderedDict([    \n",
    "            (\"reflectpad_head0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_head0\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act_head0\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad_head1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_head1\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act_head1\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad_head2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_head2\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act_head2\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"maxpool_head\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n",
    "            (\"reflectpad_head3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv_head3\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act_head3\", torch.nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "        if pretrained_path is not None:\n",
    "            self._load_weights(torch.load(pretrained_path, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    def _load_weights(self, state_dict):\n",
    "        self_dict = self.state_dict()\n",
    "        self_dict = {k: v for k, v in zip(self_dict.keys(), state_dict.values())}\n",
    "        self.load_state_dict(self_dict)\n",
    "        \n",
    "    def forward(self, x, target=\"head\", output_last_feature=True):\n",
    "        x_tail = self.tail(x)\n",
    "        x_lower_spine = self.lower_spine(x_tail)\n",
    "        x_spine = self.spine(x_lower_spine)\n",
    "        x_neck = self.neck(x_spine)\n",
    "        x_head = self.head(x_neck)\n",
    "        if output_last_feature:\n",
    "            if target == \"tail\":\n",
    "                return x_tail\n",
    "            if target == \"lower_spine\":\n",
    "                return x_lower_spine\n",
    "            if target == \"spine\":\n",
    "                return x_spine\n",
    "            if target == \"neck\":\n",
    "                return x_neck\n",
    "            return x_head\n",
    "        else:\n",
    "            if target == \"tail\":\n",
    "                return x_tail\n",
    "            if target == \"lower_spine\":\n",
    "                return x_tail, x_lower_spine\n",
    "            if target == \"spine\":\n",
    "                return x_tail, x_lower_spine, x_spine\n",
    "            if target == \"neck\":\n",
    "                return x_tail, x_lower_spine, x_spine, x_neck\n",
    "            return x_tail, x_lower_spine, x_spine, x_neck, x_head\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, level, pretrained_path=None):\n",
    "        super().__init__()\n",
    "        decoder_layers = collections.OrderedDict([\n",
    "            (\"reflectpad0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv0\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act0\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"upsample0\", torch.nn.Upsample(scale_factor=2)),\n",
    "            (\"reflectpad1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv1\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act1\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv2\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act2\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv3\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n",
    "            (\"act3\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad4\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv4\", torch.nn.Conv2d(512, 256, kernel_size=3)),\n",
    "            (\"act4\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"upsample1\", torch.nn.Upsample(scale_factor=2)),\n",
    "            (\"reflectpad5\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv5\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act5\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad6\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv6\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act6\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad7\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv7\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n",
    "            (\"act7\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad8\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv8\", torch.nn.Conv2d(256, 128, kernel_size=3)),\n",
    "            (\"act8\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"upsample2\", torch.nn.Upsample(scale_factor=2)),\n",
    "            (\"reflectpad9\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv9\", torch.nn.Conv2d(128, 128, kernel_size=3)),\n",
    "            (\"act9\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad10\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv10\", torch.nn.Conv2d(128, 64, kernel_size=3)),\n",
    "            (\"act10\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"upsample3\", torch.nn.Upsample(scale_factor=2)),\n",
    "            (\"reflectpad11\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv11\", torch.nn.Conv2d(64, 64, kernel_size=3)),\n",
    "            (\"act11\", torch.nn.ReLU(inplace=True)),\n",
    "            (\"reflectpad12\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n",
    "            (\"conv12\", torch.nn.Conv2d(64, 3, kernel_size=3))\n",
    "        ])\n",
    "        if level == 1:\n",
    "            self.layers = torch.nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-2:]))\n",
    "        elif level == 2:\n",
    "            self.layers = torch.nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-9:]))\n",
    "        elif level == 3:\n",
    "            self.layers = torch.nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-16:]))\n",
    "        elif level == 4:\n",
    "            self.layers = torch.nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-29:]))\n",
    "        elif level == 5:\n",
    "            self.layer = torch.nn.Sequential(decoder_layers)\n",
    "        else:\n",
    "            raise ValueError(\"level should be between 1 and 5\")\n",
    "        if pretrained_path is not None:\n",
    "            self._load_weights(torch.load(pretrained_path, map_location=lambda storage, loc: storage))\n",
    "            \n",
    "    def _load_weights(self, state_dict):\n",
    "        self_dict = self.state_dict()\n",
    "        self_dict = {k: v for k, v in zip(self_dict.keys(), state_dict.values())}\n",
    "        self.load_state_dict(self_dict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class StyleTransferCNN(torch.nn.Module):\n",
    "    def __init__(self, alpha=1, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        torchhub_save_dir = (pathlib.Path.home() / \".cache\" / \"torch\" / \"hub\" / \"checkpoints\")\n",
    "        torchhub_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if not (torchhub_save_dir / \"vgg_normalized_conv5_1.pth\").is_file():\n",
    "                download_from_gdrive(\"1IAOFF5rDkVei035228Qp35hcTnliyMol\", torchhub_save_dir / \"vgg_normalized_conv5_1.pth\")\n",
    "        self.encoder = NormalizedVGG(pretrained_path=(torchhub_save_dir / \"vgg_normalized_conv5_1.pth\"))\n",
    "        if pretrained:\n",
    "            if not (torchhub_save_dir / \"decoder_relu4_1.pth\").is_file():\n",
    "                download_from_gdrive(\"1kkoyNwRup9y5GT1mPbsZ_7WPQO9qB7ZZ\", torchhub_save_dir / \"decoder_relu4_1.pth\")\n",
    "            self.decoder = Decoder(level=4, pretrained_path=torchhub_save_dir / \"decoder_relu4_1.pth\")\n",
    "        else:\n",
    "            self.decoder = Decoder(level=4)\n",
    "    \n",
    "    def _apply(self, fn):\n",
    "        # redefine to move encoder and decoder to the same device the main model is on\n",
    "        super()._apply(fn)\n",
    "        self.encoder._apply(fn)\n",
    "        self.decoder._apply(fn)\n",
    "        return self\n",
    "\n",
    "    def _calc_k(self, x, max_cluster=5, threshold_min=0.1, threshold_max=0.7):\n",
    "        image = torchvision.transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "        w, h = image.size\n",
    "        w, h = self._calc_maxpool_size(w, h, 3)\n",
    "        image = image.resize((w, h))\n",
    "        image = skimage.color.rgb2lab(image).reshape(w * h, -1)\n",
    "        k = 2\n",
    "        k_means = KMeans(k, device=x.device)\n",
    "        image = torch.from_numpy(image).to(k_means.device)\n",
    "        k_means.fit(image)\n",
    "        labels = k_means.labels_\n",
    "        prev_labels = k_means.labels_\n",
    "        prev_cluster_centers = k_means.cluster_centers_\n",
    "        while True:\n",
    "            cnt = collections.Counter(labels.cpu().tolist())\n",
    "            if k <= max_cluster and (cnt.most_common()[-1][1] / (w * h) > threshold_min or cnt.most_common()[0][1] / (\n",
    "                w * h) > threshold_max):\n",
    "                if cnt.most_common()[-2][1] / (w * h) < threshold_min:\n",
    "                    labels = prev_labels\n",
    "                    cluster_centers = prev_cluster_centers\n",
    "                    k -= 1\n",
    "                    break\n",
    "                k += 1\n",
    "            else:\n",
    "                if k > max_cluster:\n",
    "                    labels = prev_labels\n",
    "                    cluster_centers = prev_cluster_centers\n",
    "                    k -= 1\n",
    "                else:\n",
    "                    labels = k_means.labels_\n",
    "                    cluster_centers = k_means.cluster_centers_\n",
    "                break\n",
    "\n",
    "            prev_labels = k_means.labels_\n",
    "            prev_cluster_centers = k_means.cluster_centers_\n",
    "\n",
    "            k_means = KMeans(k, device=x.device)\n",
    "            k_means.fit(image)\n",
    "            labels = k_means.labels_\n",
    "        \n",
    "        new_clusters = cluster_centers.norm(dim=1).argsort(descending=False).tolist()\n",
    "        new_clusters = [new_clusters.index(j) for j in range(k)]\n",
    "        cluster_centers_norm, _ = torch.sort(cluster_centers.norm(dim=1))\n",
    "        cluster_centers_norm -= cluster_centers_norm.min()\n",
    "        cluster_centers_norm /= cluster_centers_norm.max()\n",
    "\n",
    "        new_labels = torch.zeros_like(labels)\n",
    "        for i in range(k):\n",
    "            new_labels[labels == i] = new_clusters[i]\n",
    "        \n",
    "        label = new_labels.reshape(h, w)\n",
    "\n",
    "        return label, cluster_centers_norm\n",
    "\n",
    "    def _calc_maxpool_size(self, w, h, count=3):\n",
    "        if count == 3:\n",
    "            w = np.ceil(np.ceil(np.ceil(w / 2) / 2) / 2)\n",
    "            h = np.ceil(np.ceil(np.ceil(h / 2) / 2) / 2)\n",
    "        elif count == 2:\n",
    "            w = np.ceil(np.ceil(w / 2) / 2)\n",
    "            h = np.ceil(np.ceil(h / 2) / 2)\n",
    "        elif count == 1:\n",
    "            w = np.ceil(w / 2)\n",
    "            h = np.ceil(h / 2)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return int(w), int(h)\n",
    "\n",
    "    def _cluster_matching(self, content_label, style_label, content_cluster_center_norm, style_cluster_center_norm, threshold=0.25):\n",
    "        content_k = int(content_label.max().item() + 1)\n",
    "        style_k = int(style_label.max().item() + 1)\n",
    "        res = {}\n",
    "        for i in range(content_k):\n",
    "            res[i] = []\n",
    "            match = False\n",
    "            for j in range(style_k):\n",
    "                if torch.abs(content_cluster_center_norm[i] - style_cluster_center_norm[j]) <= threshold:\n",
    "                    match = True\n",
    "                    res[i].append(j)\n",
    "            if not match:\n",
    "                res[i] = [jj for jj in range(style_k)]\n",
    "        \n",
    "        return res\n",
    "\n",
    "    def _labeled_whiten_and_color(self, f_c, f_s, alpha, clabel):\n",
    "        try:\n",
    "            cc, ch, cw = f_c.shape\n",
    "            cf = (f_c * clabel).reshape(cc, -1)\n",
    "            num_nonzero = torch.sum(clabel).item() / cc\n",
    "            c_mean = (torch.sum(cf, 1) / num_nonzero).reshape(cc, 1, 1) * clabel\n",
    "            cf = (cf.reshape(cc, ch, cw) - c_mean).reshape(cc, -1)\n",
    "            \n",
    "            c_cov = torch.mm(cf, ct.t()) / (num_nonzero - 1)\n",
    "            c_u, c_e, c_v = torch.svd(c_cov)\n",
    "            c_d = c_e.pow(-0.5)\n",
    "\n",
    "            w_step1 = torch.mm(c_v, torch.diag(c_d))\n",
    "            w_step2 = torch.mm(w_step1, (c_v.t()))\n",
    "            whitened = torch.mm(w_step2, cf)\n",
    "\n",
    "            sf = f_s\n",
    "            sc, shw = sf.shape\n",
    "            s_mean = torch.mean(f_s, 1, keepdim=True)\n",
    "            sf -= s_mean\n",
    "\n",
    "            s_cov = torch.mm(sf, sf.t()) / (shw - 1)\n",
    "            s_u, s_e, s_v = torch.svd(s_cov)\n",
    "            s_d = s_e.pow(-0.5)\n",
    "\n",
    "            c_step1 = torch.mm(s_v, torch.diag(s_d))\n",
    "            c_step2 = torch.mm(c_step1, s_v.t())\n",
    "            colored = torch.mm(c_step2, whitened).reshape(cc, ch, cw)\n",
    "\n",
    "            colored += s_mean.reshape(sc, 1, 1) * clabel\n",
    "            colored_feature = alpha * colored + (1 - alpha) * (f_c * clabel)\n",
    "        except:\n",
    "            colored_feature = f_c * clabel\n",
    "        \n",
    "        return colored_feature\n",
    "\n",
    "    def generate(self, content, style):\n",
    "        cs = []\n",
    "        content_features = self.encoder(content, target=\"neck\")\n",
    "        style_features = self.encoder(style, target=\"neck\")\n",
    "\n",
    "        for c_image, s_image, c_feat, s_feat in zip(content, style, content_features, style_features):\n",
    "            content_label, content_center_norm = self._calc_k(c_image)\n",
    "            style_label, style_center_norm = self._calc_k(s_image)\n",
    "            match = self._cluster_matching(content_label, style_label, content_center_norm, style_center_norm)\n",
    "\n",
    "            cs_feature = torch.zeros_like(c_feat)\n",
    "            for i, j in match.items():\n",
    "                cl = (content_label == i).unsqueeze(dim=0).expand_as(c_feat).to(torch.float)\n",
    "                sl = torch.zeros_like(s_feat)\n",
    "                for jj in j:\n",
    "                    sl += (style_label == jj).unsqueeze(dim=0).expand_as(s_feat).to(torch.float)\n",
    "                sl = sl.to(torch.bool)\n",
    "                sub_sf = s_feat[sl].reshape(s_feat.shape[0], -1)\n",
    "                cs_feature += self._labeled_whiten_and_color(c_feat, sub_sf, self.alpha, cl)\n",
    "\n",
    "            cs.append(cs_feature.unsqueeze(dim=0))\n",
    "        cs = torch.cat(cs, dim=0)\n",
    "        out = self.decoder(cs)\n",
    "        return out\n",
    "\n",
    "    def forward(self, content, style):\n",
    "        out = self.generate(content, style)\n",
    "        content_features = self.encoder(content)\n",
    "        out_features = self.encoder(out, output_last_feature=True)\n",
    "        out_middle_features = self.encoder(out, output_last_feature=False)\n",
    "        style_middle_features = self.encoder(style, output_last_feature=False)\n",
    "        return out, content_features, out_features, out_middle_features, style_middle_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8J1UI5t-NtGB"
   },
   "outputs": [],
   "source": [
    "model = StyleTransferCNN().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mZw6gccENyqW",
    "outputId": "42707633-95cc-4731-bdd2-8f1fbfd28aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "StyleTransferCNN                         --                        --\n",
       "├─NormalizedVGG: 1-1                     [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-1                   [16, 64, 128, 128]        --\n",
       "│    │    └─Conv2d: 3-1                  [16, 3, 128, 128]         (12)\n",
       "│    │    └─ReflectionPad2d: 3-2         [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-3                  [16, 64, 128, 128]        (1,792)\n",
       "│    │    └─ReLU: 3-4                    [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-2                   [16, 128, 64, 64]         --\n",
       "│    │    └─ReflectionPad2d: 3-5         [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-6                  [16, 64, 128, 128]        (36,928)\n",
       "│    │    └─ReLU: 3-7                    [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-8               [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-9         [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-10                 [16, 128, 64, 64]         (73,856)\n",
       "│    │    └─ReLU: 3-11                   [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-3                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-12        [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-13                 [16, 128, 64, 64]         (147,584)\n",
       "│    │    └─ReLU: 3-14                   [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-15              [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-16        [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-17                 [16, 256, 32, 32]         (295,168)\n",
       "│    │    └─ReLU: 3-18                   [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-4                   [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-19        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-20                 [16, 256, 32, 32]         (590,080)\n",
       "│    │    └─ReLU: 3-21                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-22        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-23                 [16, 256, 32, 32]         (590,080)\n",
       "│    │    └─ReLU: 3-24                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-25        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-26                 [16, 256, 32, 32]         (590,080)\n",
       "│    │    └─ReLU: 3-27                   [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-28              [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-29        [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-30                 [16, 512, 16, 16]         (1,180,160)\n",
       "│    │    └─ReLU: 3-31                   [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-5                   [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-32        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-33                 [16, 512, 16, 16]         (2,359,808)\n",
       "│    │    └─ReLU: 3-34                   [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-35        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-36                 [16, 512, 16, 16]         (2,359,808)\n",
       "│    │    └─ReLU: 3-37                   [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-38        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-39                 [16, 512, 16, 16]         (2,359,808)\n",
       "│    │    └─ReLU: 3-40                   [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-41              [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-42        [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-43                 [16, 512, 8, 8]           (2,359,808)\n",
       "│    │    └─ReLU: 3-44                   [16, 512, 8, 8]           --\n",
       "├─NormalizedVGG: 1-2                     [16, 512, 16, 16]         (recursive)\n",
       "│    └─Sequential: 2-6                   [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─Conv2d: 3-45                 [16, 3, 128, 128]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-46        [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-47                 [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-48                   [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-7                   [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-49        [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-50                 [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-51                   [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-52              [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-53        [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-54                 [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-55                   [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-8                   [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-56        [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-57                 [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-58                   [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-59              [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-60        [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-61                 [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-62                   [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-9                   [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-63        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-64                 [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-65                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-66        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-67                 [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-68                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-69        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-70                 [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-71                   [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-72              [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-73        [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-74                 [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-75                   [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-10                  [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-76        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-77                 [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-78                   [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-79        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-80                 [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-81                   [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-82        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-83                 [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-84                   [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-85              [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-86        [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-87                 [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReLU: 3-88                   [16, 512, 8, 8]           --\n",
       "├─Decoder: 1-3                           [16, 3, 128, 128]         --\n",
       "│    └─Sequential: 2-11                  [16, 3, 128, 128]         --\n",
       "│    │    └─ReflectionPad2d: 3-89        [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-90                 [16, 256, 16, 16]         1,179,904\n",
       "│    │    └─ReLU: 3-91                   [16, 256, 16, 16]         --\n",
       "│    │    └─Upsample: 3-92               [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-93        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-94                 [16, 256, 32, 32]         590,080\n",
       "│    │    └─ReLU: 3-95                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-96        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-97                 [16, 256, 32, 32]         590,080\n",
       "│    │    └─ReLU: 3-98                   [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-99        [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-100                [16, 256, 32, 32]         590,080\n",
       "│    │    └─ReLU: 3-101                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-102       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-103                [16, 128, 32, 32]         295,040\n",
       "│    │    └─ReLU: 3-104                  [16, 128, 32, 32]         --\n",
       "│    │    └─Upsample: 3-105              [16, 128, 64, 64]         --\n",
       "│    │    └─ReflectionPad2d: 3-106       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-107                [16, 128, 64, 64]         147,584\n",
       "│    │    └─ReLU: 3-108                  [16, 128, 64, 64]         --\n",
       "│    │    └─ReflectionPad2d: 3-109       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-110                [16, 64, 64, 64]          73,792\n",
       "│    │    └─ReLU: 3-111                  [16, 64, 64, 64]          --\n",
       "│    │    └─Upsample: 3-112              [16, 64, 128, 128]        --\n",
       "│    │    └─ReflectionPad2d: 3-113       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-114                [16, 64, 128, 128]        36,928\n",
       "│    │    └─ReLU: 3-115                  [16, 64, 128, 128]        --\n",
       "│    │    └─ReflectionPad2d: 3-116       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-117                [16, 3, 128, 128]         1,731\n",
       "├─NormalizedVGG: 1-4                     [16, 512, 8, 8]           (recursive)\n",
       "│    └─Sequential: 2-12                  [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─Conv2d: 3-118                [16, 3, 128, 128]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-119       [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-120                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-121                  [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-13                  [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-122       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-123                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-124                  [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-125             [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-126       [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-127                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-128                  [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-14                  [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-129       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-130                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-131                  [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-132             [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-133       [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-134                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-135                  [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-15                  [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-136       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-137                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-138                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-139       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-140                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-141                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-142       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-143                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-144                  [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-145             [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-146       [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-147                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-148                  [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-16                  [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-149       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-150                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-151                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-152       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-153                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-154                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-155       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-156                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-157                  [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-158             [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-159       [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-160                [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReLU: 3-161                  [16, 512, 8, 8]           --\n",
       "├─NormalizedVGG: 1-5                     [16, 512, 8, 8]           (recursive)\n",
       "│    └─Sequential: 2-17                  [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─Conv2d: 3-162                [16, 3, 128, 128]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-163       [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-164                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-165                  [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-18                  [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-166       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-167                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-168                  [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-169             [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-170       [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-171                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-172                  [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-19                  [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-173       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-174                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-175                  [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-176             [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-177       [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-178                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-179                  [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-20                  [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-180       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-181                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-182                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-183       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-184                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-185                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-186       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-187                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-188                  [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-189             [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-190       [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-191                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-192                  [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-21                  [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-193       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-194                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-195                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-196       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-197                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-198                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-199       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-200                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-201                  [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-202             [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-203       [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-204                [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReLU: 3-205                  [16, 512, 8, 8]           --\n",
       "├─NormalizedVGG: 1-6                     [16, 64, 128, 128]        (recursive)\n",
       "│    └─Sequential: 2-22                  [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─Conv2d: 3-206                [16, 3, 128, 128]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-207       [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-208                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-209                  [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-23                  [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-210       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-211                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-212                  [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-213             [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-214       [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-215                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-216                  [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-24                  [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-217       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-218                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-219                  [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-220             [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-221       [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-222                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-223                  [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-25                  [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-224       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-225                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-226                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-227       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-228                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-229                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-230       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-231                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-232                  [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-233             [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-234       [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-235                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-236                  [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-26                  [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-237       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-238                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-239                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-240       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-241                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-242                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-243       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-244                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-245                  [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-246             [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-247       [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-248                [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReLU: 3-249                  [16, 512, 8, 8]           --\n",
       "├─NormalizedVGG: 1-7                     [16, 64, 128, 128]        (recursive)\n",
       "│    └─Sequential: 2-27                  [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─Conv2d: 3-250                [16, 3, 128, 128]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-251       [16, 3, 130, 130]         --\n",
       "│    │    └─Conv2d: 3-252                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-253                  [16, 64, 128, 128]        --\n",
       "│    └─Sequential: 2-28                  [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-254       [16, 64, 130, 130]        --\n",
       "│    │    └─Conv2d: 3-255                [16, 64, 128, 128]        (recursive)\n",
       "│    │    └─ReLU: 3-256                  [16, 64, 128, 128]        --\n",
       "│    │    └─MaxPool2d: 3-257             [16, 64, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d: 3-258       [16, 64, 66, 66]          --\n",
       "│    │    └─Conv2d: 3-259                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-260                  [16, 128, 64, 64]         --\n",
       "│    └─Sequential: 2-29                  [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-261       [16, 128, 66, 66]         --\n",
       "│    │    └─Conv2d: 3-262                [16, 128, 64, 64]         (recursive)\n",
       "│    │    └─ReLU: 3-263                  [16, 128, 64, 64]         --\n",
       "│    │    └─MaxPool2d: 3-264             [16, 128, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-265       [16, 128, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-266                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-267                  [16, 256, 32, 32]         --\n",
       "│    └─Sequential: 2-30                  [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-268       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-269                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-270                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-271       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-272                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-273                  [16, 256, 32, 32]         --\n",
       "│    │    └─ReflectionPad2d: 3-274       [16, 256, 34, 34]         --\n",
       "│    │    └─Conv2d: 3-275                [16, 256, 32, 32]         (recursive)\n",
       "│    │    └─ReLU: 3-276                  [16, 256, 32, 32]         --\n",
       "│    │    └─MaxPool2d: 3-277             [16, 256, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-278       [16, 256, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-279                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-280                  [16, 512, 16, 16]         --\n",
       "│    └─Sequential: 2-31                  [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReflectionPad2d: 3-281       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-282                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-283                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-284       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-285                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-286                  [16, 512, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d: 3-287       [16, 512, 18, 18]         --\n",
       "│    │    └─Conv2d: 3-288                [16, 512, 16, 16]         (recursive)\n",
       "│    │    └─ReLU: 3-289                  [16, 512, 16, 16]         --\n",
       "│    │    └─MaxPool2d: 3-290             [16, 512, 8, 8]           --\n",
       "│    │    └─ReflectionPad2d: 3-291       [16, 512, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-292                [16, 512, 8, 8]           (recursive)\n",
       "│    │    └─ReLU: 3-293                  [16, 512, 8, 8]           --\n",
       "==========================================================================================\n",
       "Total params: 16,450,191\n",
       "Trainable params: 3,505,219\n",
       "Non-trainable params: 12,944,972\n",
       "Total mult-adds (G): 631.83\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 981.47\n",
       "Params size (MB): 65.80\n",
       "Estimated Total Size (MB): 1053.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchinfo.summary(model, ((int(BATCH_SIZE), 3, IMAGE_SIZE, IMAGE_SIZE), (int(BATCH_SIZE), 3, IMAGE_SIZE, IMAGE_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gqDpk_ZsN_Aj",
    "outputId": "cd70207b-35b3-42f4-8760-7931dfe74db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 13 05:35:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   66C    P0    N/A /  N/A |   1271MiB /  3020MiB |     24%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     25444      C   ...irtualenvs/dls/bin/python     1267MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jeab14LGOASp"
   },
   "source": [
    "# Defining loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "soQqtiY4OBzQ"
   },
   "outputs": [],
   "source": [
    "class StyleTransferLoss(torch.nn.Module):\n",
    "    def __init__(self, lam=10):\n",
    "        super().__init__()\n",
    "        self.lam = lam\n",
    "\n",
    "    def _style_loss(self, content_middle, style_middle):\n",
    "        loss = 0\n",
    "        inst_norm = AdaptiveInstanceNorm2d()\n",
    "        for c, s in zip(content_middle, style_middle):\n",
    "            c_mean, c_std = inst_norm._get_mean(c), inst_norm._get_std(c)\n",
    "            s_mean, s_std = inst_norm._get_mean(s), inst_norm._get_std(s)\n",
    "            loss += F.mse_loss(c_mean, s_mean) + F.mse_loss(c_std, s_std)\n",
    "        return loss\n",
    "\n",
    "    def _content_loss(self, output_feats, content_feats):\n",
    "        return F.mse_loss(output_feats, content_feats)\n",
    "\n",
    "    def forward(self, output_feats, content_feats, output_middle, style_middle):\n",
    "        return self._content_loss(output_feats, content_feats) + self.lam * self._style_loss(output_middle, style_middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZEn1pE3QHCR"
   },
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "woAUbEidQH5o"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = StyleTransferLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvvBnUCbQUhh",
    "outputId": "ba0f6cd5-ea2a-4216-8006-d2449cd5591f"
   },
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "history_nst = train_model(train_loader, val_loader, model, optimizer, criterion, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elQ-W5hLndcV",
    "outputId": "1aac8b34-d3e8-4c52-e33d-43a3167f889b"
   },
   "outputs": [],
   "source": [
    "plot_loss(history_nst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4aH3RNgnkgF"
   },
   "source": [
    "# Validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CQsnW7xnpqU",
    "outputId": "116ca5c9-f32a-48d5-8b15-9395a3f7901b"
   },
   "outputs": [],
   "source": [
    "test_content, test_style = next(iter(val_loader))\n",
    "test_styled = style_transfer(model, test_content, test_style)\n",
    "plot_pics(Denormalize(mean=NORMALIZATION_PARAMS[\"mean\"], std=NORMALIZATION_PARAMS[\"std\"])(test_styled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYtSSwoOoXwO"
   },
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TR8PzCjsoYdz"
   },
   "outputs": [],
   "source": [
    "save_model(\"nst_vgg_semst.pth\", model, mode=\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    save_model(f\"nst_vgg_semst_torchscript.pth\", model, mode=\"torchscript\")\n",
    "except Exception: # not sure which one torch.jit.script will throw if an operation is unscriptable\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinitialize model with pretrained weights and save as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clear out the previous one first\n",
    "model = model.cpu()\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleTransferCNN(pretrained=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 2.95 GiB total capacity; 2.19 GiB already allocated; 36.94 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25444/3658577581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check out the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_style\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_styled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_style\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_pics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNORMALIZATION_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNORMALIZATION_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_styled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25444/1199026812.py\u001b[0m in \u001b[0;36mstyle_transfer\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mstyled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstyled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25444/2033060096.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, content, style)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mcontent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neck\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0mstyle_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neck\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25444/2033060096.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target, output_last_feature)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"head\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_last_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx_lower_spine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_spine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx_spine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lower_spine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dls/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 2.95 GiB total capacity; 2.19 GiB already allocated; 36.94 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Check out the outputs\n",
    "test_content, test_style = next(iter(val_loader))\n",
    "test_styled = style_transfer(model, test_content, test_style)\n",
    "plot_pics(Denormalize(mean=NORMALIZATION_PARAMS[\"mean\"], std=NORMALIZATION_PARAMS[\"std\"])(test_styled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"nst_vgg_semst_pretrained.pth\", model, mode=\"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    save_model(f\"nst_vgg_semst_pretrained_torchscript.pth\", mode=\"torchscript\")\n",
    "except Exception: # not sure which one torch.jit.script will throw if an operation is unscriptable\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
