{"cells":[{"cell_type":"markdown","metadata":{"id":"ud24EThsJ5Nh"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:07.585140Z","iopub.status.busy":"2022-02-05T23:28:07.584907Z","iopub.status.idle":"2022-02-05T23:28:17.137923Z","shell.execute_reply":"2022-02-05T23:28:17.137091Z","shell.execute_reply.started":"2022-02-05T23:28:07.585075Z"},"id":"DQv5KY_LLaf5","outputId":"a2867670-47aa-4343-af7a-2ec14af806f4","trusted":true},"outputs":[],"source":["!pip install torchinfo"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:17.140436Z","iopub.status.busy":"2022-02-05T23:28:17.140153Z","iopub.status.idle":"2022-02-05T23:28:20.106313Z","shell.execute_reply":"2022-02-05T23:28:20.105567Z","shell.execute_reply.started":"2022-02-05T23:28:17.140399Z"},"id":"eOhvtnD5J49-","trusted":true},"outputs":[],"source":["import collections\n","import copy\n","import glob\n","import io\n","import itertools\n","import os\n","import pathlib\n","import pickle\n","import random\n","import shutil\n","import time\n","import warnings\n","import zipfile\n","warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n","\n","import IPython\n","import IPython.display\n","\n","import requests\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import skimage\n","import skimage.color\n","import skimage.io\n","import skimage.transform\n","\n","import tqdm.auto as tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import torchvision\n","\n","import torchinfo"]},{"cell_type":"markdown","metadata":{"id":"a20tbSYkLmHc"},"source":["# Setting random seeds"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.107880Z","iopub.status.busy":"2022-02-05T23:28:20.107636Z","iopub.status.idle":"2022-02-05T23:28:20.116092Z","shell.execute_reply":"2022-02-05T23:28:20.115267Z","shell.execute_reply.started":"2022-02-05T23:28:20.107849Z"},"id":"mxq29ZwVLqJz","trusted":true},"outputs":[],"source":["RANDOM_STATE = 42\n","random.seed(RANDOM_STATE)\n","os.environ['PYTHONHASHSEED'] = str(RANDOM_STATE)\n","np.random.seed(RANDOM_STATE)\n","torch.manual_seed(RANDOM_STATE)\n","torch.cuda.manual_seed(RANDOM_STATE)\n","torch.cuda.manual_seed_all(RANDOM_STATE)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.118945Z","iopub.status.busy":"2022-02-05T23:28:20.118671Z","iopub.status.idle":"2022-02-05T23:28:20.123717Z","shell.execute_reply":"2022-02-05T23:28:20.122969Z","shell.execute_reply.started":"2022-02-05T23:28:20.118911Z"},"trusted":true},"outputs":[],"source":["if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\") != \"\":\n","    RUNNER = \"kaggle\"\n","elif \"google.colab\" in str(IPython.get_ipython()):\n","    RUNNER = \"colab\"\n","else:\n","    # assume running on a local machine\n","    RUNNER = \"local\""]},{"cell_type":"markdown","metadata":{"id":"8aWsRicMMXxH"},"source":["# Determining device"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.125440Z","iopub.status.busy":"2022-02-05T23:28:20.124942Z","iopub.status.idle":"2022-02-05T23:28:20.172923Z","shell.execute_reply":"2022-02-05T23:28:20.172224Z","shell.execute_reply.started":"2022-02-05T23:28:20.125406Z"},"id":"XtZOpwh-MZvB","outputId":"2b14ded5-ee51-44de-c5a1-4f544842cd53","trusted":true},"outputs":[],"source":["DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"K--tlf-bNvPJ"},"source":["# Setting globals"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.174495Z","iopub.status.busy":"2022-02-05T23:28:20.174165Z","iopub.status.idle":"2022-02-05T23:28:20.182991Z","shell.execute_reply":"2022-02-05T23:28:20.182225Z","shell.execute_reply.started":"2022-02-05T23:28:20.174459Z"},"id":"moKn5k7UOBsg","trusted":true},"outputs":[],"source":["BATCH_SIZE = 8\n","IMAGE_SIZE = 256\n","NORMALIZATION_PARAMS = {\"mean\": (0.485, 0.456, 0.406),\n","                        \"std\": (0.229, 0.224, 0.225)}\n","plt.rcParams[\"figure.figsize\"] = (15, 15)\n","USE_SMALLER_DATASET = False"]},{"cell_type":"markdown","metadata":{"id":"vCHZO0NlS9kS"},"source":["# Helper functions and classes"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.184785Z","iopub.status.busy":"2022-02-05T23:28:20.184355Z","iopub.status.idle":"2022-02-05T23:28:20.197725Z","shell.execute_reply":"2022-02-05T23:28:20.197101Z","shell.execute_reply.started":"2022-02-05T23:28:20.184639Z"},"id":"brHE-1DxTIlg","trusted":true},"outputs":[],"source":["class Denormalize():\n","    def __init__(self, mean, std):\n","        self.mean = mean\n","        self.std = std\n","    \n","    def __call__(self, tensor):\n","        for t, m ,s in zip(tensor, self.mean, self.std):\n","            t.mul_(s).add_(m)\n","        return tensor\n","\n","class FromTensor():\n","    def __call__(self, tensor):\n","        image = tensor.permute(1, 2, 0).numpy()\n","        return image\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","class StyleTransferDataset(torch.utils.data.Dataset):\n","    def __init__(self, content_dir, style_dir, transforms=None):\n","        content_images = glob.glob(content_dir + \"/*\")\n","        style_images = glob.glob(style_dir + \"/*\")\n","        self.images = list(zip(content_images, style_images))\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        content, style = self.images[idx]\n","        content_img = skimage.io.imread(content)\n","        if len(content_img.shape) < 3:\n","            content_img = skimage.color.gray2rgb(content_img)\n","        style_img = skimage.io.imread(style)\n","        if len(style_img.shape) < 3:\n","            content_img = skimage.color.gray2rgb(content_img)\n","        content_img = torchvision.transforms.ToTensor()(content_img)\n","        style_img = torchvision.transforms.ToTensor()(style_img)\n","        if self.transforms:\n","            content_img, style_img = self.transforms(content_img), self.transforms(style_img)\n","        return content_img, style_img"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.199989Z","iopub.status.busy":"2022-02-05T23:28:20.199578Z","iopub.status.idle":"2022-02-05T23:28:20.209376Z","shell.execute_reply":"2022-02-05T23:28:20.208528Z","shell.execute_reply.started":"2022-02-05T23:28:20.199954Z"},"id":"pm0u7GMPXpbq","trusted":true},"outputs":[],"source":["class AdaptiveInstanceNorm2d(torch.nn.Module):\n","    def __init__(self, eps=1e-6):\n","        super().__init__()\n","        self.eps = eps\n","\n","    def _get_mean(self, features):\n","        batch_size, c = features.size()[:2]\n","        features_mean = features.reshape(batch_size, c, -1).mean(dim=2).reshape(batch_size, c, 1, 1)\n","        return features_mean\n","    \n","    def _get_std(self, features):\n","        batch_size, c = features.size()[:2]\n","        features_std = features.reshape(batch_size, c, -1).std(dim=2).reshape(batch_size, c, 1, 1) + self.eps\n","        return features_std\n","\n","    def forward(self, content, style):\n","        content_mean, content_std = self._get_mean(content), self._get_std(content)\n","        style_mean, style_std = self._get_mean(style), self._get_std(style)\n","        normalized = style_std * (content - content_mean) / content_std + style_mean\n","        return normalized"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def download_from_gdrive(id, dest):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","    session = requests.Session()\n","    response = session.get(URL, params={\"id\": id}, stream=True)\n","    token = get_confirm_token(response)\n","    if token:\n","        params = {\"id\": id, \"confirm\": token}\n","        response = session.get(URL, params=params, stream=True)\n","\n","    save_response_content(response, dest)\n","\n","def get_confirm_token(response):\n","    for k, v in response.cookies.items():\n","        if k.startswith(\"download_warning\"):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, dest):\n","    with open(dest, \"wb\") as f:\n","        for chunk in tqdm.tqdm(response.iter_content(32768), desc=\"Downloading file\", unit=\"chunks\", unit_scale=False):\n","            if chunk:\n","                f.write(chunk)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class KMeans:\n","    def __init__(self, n_clusters, device=\"cpu\", tol=1e-4, init=\"kmeans++\"):\n","        self.n_clusters = n_clusters\n","        self.device = device\n","        self.tol = tol\n","        self.init = init\n","        self._labels = None\n","        self._cluster_centers = None\n","\n","    def _initial_state(self, data):\n","        if self.init == \"kmeans++\":\n","            n, c = data.shape\n","            dis = torch.zeros((n, self.n_clusters), device=self.device)\n","            initial_state = torch.zeros((self.n_clusters, c), device=self.device)\n","            pr = np.repeat(1 / n, n)\n","            initial_state[0, :] = data[np.random.choice(np.arange(n), p=pr)]\n","            dis[:, 0] = torch.sum((data - initial_state[0, :]) ** 2, dim=1)\n","\n","            for k in range(1, self.n_clusters):\n","                pr = torch.sum(dis, dim=1)/ torch.sum(dis)\n","                initial_state[k, :] = data[np.random.choice(np.arange(n), p=pr.cpu().numpy())]\n","                dis[:, k] = torch.sum((data - initial_state[k, :]) ** 2, dim=1)\n","        else:\n","            n = data.shape[0]\n","            indices = np.random.choice(n, self.n_clusters)\n","            initial_state = data[indices]\n","\n","        return initial_state\n","\n","    @staticmethod\n","    def pairwise_distance(data1, data2=None):\n","        if data2 is None:\n","            data2 = data1\n","\n","        a = data1.unsqueeze(dim=1)\n","        b = data2.unsqueeze(dim=0)\n","\n","        dis = (a - b) ** 2.0\n","        dis = dis.sum(dim=-1).squeeze()\n","        return dis\n","    \n","    def fit(self, data):\n","        data = data.to(torch.float32)\n","        cluster_centers = self._initial_state(data)\n","\n","        while True:\n","            dis = self.pairwise_distance(data, cluster_centers)\n","            labels = torch.argmin(dis, dim=1)\n","            cluster_centers_pre = cluster_centers.clone()\n","\n","            for index in range(self.n_clusters):\n","                selected = labels == index\n","                if selected.any():\n","                    selected = data[labels == index]\n","                    cluster_centers[index] = selected.mean(dim=0)\n","                else:\n","                    cluster_centers[index] = torch.zeros_like(cluster_centers[0], device=self.device)\n","            \n","            center_shift = torch.sum(torch.sqrt(torch.sum((cluster_centers - cluster_centers_pre) ** 2, dim=1)))\n","            if center_shift ** 2 < self.tol:\n","                break\n","        \n","        self._labels = labels\n","        self._cluster_centers = cluster_centers\n","\n","    @property\n","    def labels_(self):\n","        return self._labels\n","    \n","    @property\n","    def cluster_centers_(self):\n","        return self._cluster_centers"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.211235Z","iopub.status.busy":"2022-02-05T23:28:20.210900Z","iopub.status.idle":"2022-02-05T23:28:20.229300Z","shell.execute_reply":"2022-02-05T23:28:20.228506Z","shell.execute_reply.started":"2022-02-05T23:28:20.211196Z"},"id":"5-Af7Ln7bn_K","trusted":true},"outputs":[],"source":["def fit_epoch(data_train, model, optimizer, criterion, epoch, epochs):\n","    model.train()\n","    running_loss = 0.0\n","    processed_data = 0\n","    styled = []\n","    for content, style in tqdm.tqdm(data_train, desc=f\"Fitting epoch {epoch + 1}/{epochs}\", unit=\"batch\", unit_scale=False):\n","        try:\n","            content, style = content.to(DEVICE), style.to(DEVICE)\n","            optimizer.zero_grad()\n","            output, output_features, content_features, output_middle, style_middle = model(content, style)\n","            loss = criterion(output_features, content_features, content_middle, style_middle)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * content.size(0)\n","            processed_data += content.size(0)\n","            styled.append(output.detach().cpu())\n","        finally:\n","            content, style = content.cpu(), style.cpu()\n","            del content, style\n","            torch.cuda.empty_cache()\n","    train_loss = running_loss / processed_data\n","    return torch.cat(styled, dim=0), train_loss\n","\n","def fit_epoch(data_val, model, optimizer, criterion, epoch, epochs):\n","    model.eval()\n","    running_loss = 0.0\n","    processed_data = 0\n","    styled = []\n","    for content, style in tqdm.tqdm(data_val, desc=f\"Fitting epoch {epoch + 1}/{epochs}\", unit=\"batch\", unit_scale=False):\n","        try:\n","            content, style = content.to(DEVICE), style.to(DEVICE)\n","            with torch.no_grad():\n","                output, output_feats, content_feats, output_middle, style_middle = model(content, style)\n","                loss = criterion(output_feats, content_feats, content_middle, style_middle)\n","            running_loss += loss.item() * content.size(0)\n","            processed_data += content.size(0)\n","            styled.append(output.detach().cpu())\n","        finally:\n","            content, style = content.cpu(), style.cpu()\n","            del content, style\n","            torch.cuda.empty_cache()\n","    val_loss = running_loss / processed_data\n","    return torch.cat(styled, dim=0), val_loss\n","\n","def train_model(data_train, data_val, model, optimizer, criterion, epochs, start_epoch=0, checkpoint_cooldown=10):\n","    history = []\n","    prev_lr = optimizer.param_groups[0][\"lr\"]\n","    start_time = time.time()\n","    with tqdm.tqdm(desc=\"Epoch\", total=epochs, unit=\"epoch\", unit_scale=False) as pbar:\n","        for epoch in range(epochs):\n","            try:\n","                _, train_loss = fit_epoch(data_train, model, optimizer, criterion, epoch, epochs)\n","                output, val_loss = eval_epoch(data_val, model, optimizer, criterion, epoch, epochs)\n","                IPython.display.clear_output(wait=True)\n","                history.append((train_loss, val_loss, optimizer.param_groups[0][\"lr\"]))\n","                show_pics_train(data_val, output, history[-1], epoch, 6)\n","                pbar.update(1)\n","                pbar.refresh()\n","\n","                if (epoch + 1) % checkpoint_cooldown == 0:\n","                    save_model(f\"nst_model_{epoch + 1}.tar\", mode=\"training\", model=model, optimizer=optimizer, loss=criterion, history=history, epoch=epoch)\n","            except KeyboardInterrupt as stop:\n","                tqdm.tqdm.write(f\"Training interrupted at epoch {epoch + 1}. Returning history\")\n","                return history\n","    end_time = time.time()\n","    train_time = end_time - start_time\n","    tqdm.tqdm.write(f\"Overall training time: {train_time: 0.1f} seconds\")\n","    return history"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.234003Z","iopub.status.busy":"2022-02-05T23:28:20.233263Z","iopub.status.idle":"2022-02-05T23:28:20.250908Z","shell.execute_reply":"2022-02-05T23:28:20.249664Z","shell.execute_reply.started":"2022-02-05T23:28:20.233965Z"},"id":"rdct7WZbdCki","trusted":true},"outputs":[],"source":["def show_pics_train(data_val, output, stats, epoch, sample_size):\n","    log_template = \"Styled images on epoch {ep: 03d}.\\n\\\n","    Train loss: {t_loss: 0.4f}, validation loss: {v_loss: 0.4f}\"\n","    content, style = next(iter(data_val))\n","    content = content[:sample_size]\n","    style = style[:sample_size]\n","    denorm = Denormalize(mean=NORMALIZATION_PARAMS[\"mean\"], std=NORMALIZATION_PARAMS[\"std\"])\n","    styled = denorm(output[:sample_size]).permute(0, 2, 3, 1)\n","    content = denorm(content).permute(0, 2, 3, 1)\n","    style = denorm(style).permute(0, 2, 3, 1)\n","    for i in range(sample_size):\n","        plt.subplot(3, sample_size, i + 1)\n","        plt.imshow(np.clip(content[i].squeeze().numpy(), 0, 1))\n","        plt.title(\"Content\")\n","        plt.axis(\"off\")\n","\n","        plt.subplot(3, sample_size, i + 1 + sample_size)\n","        plt.imshow(np.clip(style[i].squeeze().numpy(), 0, 1))\n","        plt.title(\"Style\")\n","        plt.axis(\"off\")\n","\n","        plt.subplot(3, sample_size, i + 1 + 2 * sample_size)\n","        plt.imshow(np.clip(styled[i].squeeze().numpy(), 0, 1))\n","        plt.title(\"Styled\")\n","        plt.axis(\"off\")\n","    plt.suptitle(log_template.format(ep=epoch + 1, t_loss=stats[0], v_loss=stats[1]))\n","    plt.show()\n","\n","def plot_pics(pics, sample_size=6):\n","    for i in range(sample_size):\n","        plt.subplot(2, sample_size // 2 + 1, i + 1)\n","        image = pics[i]\n","        image = image.permute(1, 2, 0)\n","        plt.imshow(image.squeeze().numpy())\n","        plt.title(\"Images\")\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","def plot_loss(history):\n","    loss, _ = zip(*history)\n","    plt.figure(figsize=(15, 9))\n","    plt.plot(loss, label=\"Train loss\")\n","    plt.legend(loc=\"best\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","def plot_learn_rate(history):\n","    _, _, learn_rate = zip(*history)\n","    plt.figure(figsize=(15, 9))\n","    plt.plot(learn_rate, label=\"Learn rate\")\n","    plt.legend(loc=\"best\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Learn rate\")\n","    plt.show()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.253171Z","iopub.status.busy":"2022-02-05T23:28:20.252701Z","iopub.status.idle":"2022-02-05T23:28:20.262872Z","shell.execute_reply":"2022-02-05T23:28:20.262096Z","shell.execute_reply.started":"2022-02-05T23:28:20.253131Z"},"id":"P6GU1rxaxFtU","trusted":true},"outputs":[],"source":["def style_transfer(model, content, style):\n","    model.eval()\n","    try:\n","        content, style = content.to(DEVICE), style.to(DEVICE)\n","        if content.dim() != 4:\n","            content = content.unsqueeze(0)\n","        if style.dim() != 4:\n","            style = style.unsqueeze(0)\n","        with torch.no_grad():\n","            styled = model.generate(content, style)\n","        styled = styled.detach().cpu()\n","    finally:\n","        content, style = content.cpu(), style.cpu()\n","        del content, style\n","        torch.cuda.empty_cache()\n","    return styled"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.264908Z","iopub.status.busy":"2022-02-05T23:28:20.264602Z","iopub.status.idle":"2022-02-05T23:28:20.277838Z","shell.execute_reply":"2022-02-05T23:28:20.276976Z","shell.execute_reply.started":"2022-02-05T23:28:20.264871Z"},"id":"BW1LsS03xp-s","trusted":true},"outputs":[],"source":["def save_model(path, model, mode=\"inference\", **kwargs):\n","    if mode == \"training\":\n","        torch.save({\n","            \"epoch\": kwargs[\"epoch\"],\n","            \"model_state_dict\": model.state_dict(),\n","            \"optimizer_state_dict\": kwargs[\"optimizer\"].state_dict(),\n","            \"loss\": kwargs[\"loss\"],\n","            \"history\": kwargs[\"history\"]},\n","            path)\n","    else:\n","        torch.save(model, path)\n","\n","def load_model(path, model_arch=None, mode=\"inference\", optim_class=None, optim_kwargs=None):\n","    if mode == \"training\":\n","        if not optim_class:\n","            raise ValueError(\"Optimizer class required to load a model saved for training.\")\n","        if not model_arch:\n","            raise ValueError(\"Model architecture required to load a model saved for training.\")\n","        model = model_arch()\n","        checkpoint = torch.load(path)\n","        model.load_state_dict(checkpoint[\"model_state_dict\"])\n","        if not optim_kwargs:\n","            optim = optim_class(model.parameters())\n","        else:\n","            optim = optim_class(model.parameters(), **optim_kwargs)\n","        optim.load_state_dict(checkpoint[\"optim_state_dict\"])\n","        epoch = checkpoint[\"epoch\"]\n","        loss = checkpoint[\"loss\"]\n","        history = checkpoint[\"history\"]\n","        model.eval()\n","        return model, optim, epoch, loss, history\n","    else:\n","        model = torch.load(path)\n","        model.eval()\n","        return model\n","\n","def save_history(path, history):\n","    with open(path, \"wb\") as f:\n","        pickle.dump(history, f)\n","\n","def load_history(path):\n","    with open(path, \"rb\") as f:\n","        history = pickle.load(f)\n","        \n","    return history"]},{"cell_type":"markdown","metadata":{"id":"okbAd8vi0d0y"},"source":["# Downloading data"]},{"cell_type":"markdown","metadata":{},"source":["There are different ways to download required data depending on runner type, and different requirements for those to work.\n","\n","If you are:\n","* Running the notebook in a Kaggle session: add the `shaorrran/coco-wikiart-nst-dataset-512-100000` dataset to the session.\n","* Running the notebook in Google Colab: upload your `kaggle.json` file into the session.\n","* Running the notebook locally: have Kaggle API installed and your token ready."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:28:20.279901Z","iopub.status.busy":"2022-02-05T23:28:20.279545Z","iopub.status.idle":"2022-02-05T23:28:20.317782Z","shell.execute_reply":"2022-02-05T23:28:20.316795Z","shell.execute_reply.started":"2022-02-05T23:28:20.279794Z"},"trusted":true},"outputs":[],"source":["DATASET_NAME = \"shaorrran/cocowikiart-nst-dataset-small\" if USE_SMALLER_DATASET \\\n","else \"shaorrran/coco-wikiart-nst-dataset-512-100000\"\n","if RUNNER == \"kaggle\":\n","    name = DATASET_NAME.split(\"/\")[1]\n","    DATASET_PATH = f\"/kaggle/input/{name}\"\n","elif RUNNER == \"colab\":\n","    from google.colab import files\n","    files.upload()\n","    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n","    !mv kaggle.json /root/.kaggle/kaggle.json\n","    !chmod 600 /root/.kaggle/kaggle.json\n","    !kaggle datasets download -d {DATASET_NAME} --unzip\n","    DATASET_PATH = os.getcwd()\n","else:\n","    if not os.exists(\"content.zip\") or os.exists(\"style.zip\") \\\n","    and not (os.path.isdir(\"content\") and os.path.isdir(\"style\")):\n","        !kaggle datasets download -d {DATASET_NAME} --unzip\n","    else:\n","        with zipfile.ZipFile(\"content.zip\", \"r\") as archive:\n","            for member in tqdm.tqdm(archive.namelist(), desc=\"Extracting\", unit=\"files\", unit_scale=False):\n","                archive.extract(member, os.getcwd())\n","        with zipfile.ZipFile(\"style.zip\", \"r\") as archive:\n","            for member in tqdm.tqdm(archive.namelist(), desc=\"Extracting\", unit=\"files\", unit_scale=False):\n","                archive.extract(member, os.getcwd())\n","        !rm content.zip\n","        !rm style.zip\n","    DATASET_PATH = os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"v6rcgpQjGLAV"},"source":["# Creating Dataset and Dataloaders"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:29:41.594268Z","iopub.status.busy":"2022-02-05T23:29:41.593567Z","iopub.status.idle":"2022-02-05T23:29:44.910059Z","shell.execute_reply":"2022-02-05T23:29:44.909200Z","shell.execute_reply.started":"2022-02-05T23:29:41.594229Z"},"id":"VAYtGJ6IGKCG","trusted":true},"outputs":[],"source":["data = StyleTransferDataset(os.path.join(DATASET_PATH, \"content\"), os.path.join(DATASET_PATH, \"style\"), \n","                            transforms=torchvision.transforms.Compose([\n","                                torchvision.transforms.RandomCrop(IMAGE_SIZE),\n","                                torchvision.transforms.Normalize(\n","                                mean=NORMALIZATION_PARAMS[\"mean\"],\n","                                std=NORMALIZATION_PARAMS[\"std\"],\n","                            )]))\n","data_train, data_val = torch.utils.data.random_split(data, \n","                                                     [int(0.95 * len(data)), len(data) - int(0.95 * len(data))], \n","                                                     generator=torch.Generator().manual_seed(RANDOM_STATE))\n","train_loader = torch.utils.data.DataLoader(data_train, batch_size=int(BATCH_SIZE), shuffle=True, \n","                                           num_workers=torch.multiprocessing.cpu_count(), \n","                                           pin_memory=True, \n","                                           drop_last=True)\n","val_loader = torch.utils.data.DataLoader(data_val, batch_size=int(BATCH_SIZE), shuffle=False, \n","                                           num_workers=torch.multiprocessing.cpu_count(), \n","                                           pin_memory=True, \n","                                           drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"_kBHl_xKIMqs"},"source":["# Defining models"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:10.107864Z","iopub.status.busy":"2022-02-05T23:30:10.107543Z","iopub.status.idle":"2022-02-05T23:30:10.132121Z","shell.execute_reply":"2022-02-05T23:30:10.131361Z","shell.execute_reply.started":"2022-02-05T23:30:10.107827Z"},"id":"VlbOZCbrIN7N","trusted":true},"outputs":[],"source":["class NormalizedVGG(torch.nn.Module):\n","    def __init(self, pretrained_path=None):\n","        super().__init__()\n","        self.tail = torch.nn.Sequential(collections.OrderedDict([\n","            (\"conv_inital\", torch.nn.Conv2d(3, 3, kernel_size=1)),\n","            (\"reflectpad_tail\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_tail\", torch.nn.Conv2d(3, 64, kernel_size=3)),\n","            (\"act_tail\", torch.nn.ReLU(inplace=True))\n","        ]))\n","        self.lower_spine = torch.nn.Sequential(collections.OrderedDict([\n","            (\"reflectpad_lspine0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_lspine0\", torch.nn.Conv2d(64, 64, kernel_size=3)),\n","            (\"act_lspine0\", torch.nn.ReLU(inplace=True)),\n","            (\"maxpool_lspine\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n","            (\"reflectpad_lspine1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_lspine1\", torch.nn.Conv2d(64, 128, kernel_size=3)),\n","            (\"act_lspine1\", torch.nn.ReLU(inplace=True))\n","        ]))\n","        self.spine = torch.nn.Sequential(collections.OrderedDict([\n","            (\"reflectpad_spine0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_spine0\", torch.nn.Conv2d(128, 128, kernel_size=3)),\n","            (\"act_spine0\", torch.nn.ReLU(inplace=True)),\n","            (\"maxpool_spine\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n","            (\"reflectpad_spine1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_spine1\", torch.nn.Conv2d(128, 256, kernel_size=3)),\n","            (\"act_spine1\", torch.nn.ReLU(inplace=True))\n","        ]))\n","        self.neck = torch.nn.Sequential(collections.OrderedDict([\n","            (\"reflectpad_neck0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_neck0\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act_neck0\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad_neck1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_neck1\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act_neck1\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad_neck2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_neck2\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act_neck2\", torch.nn.ReLU(inplace=True)),\n","            (\"maxpool_neck\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n","            (\"reflectpad_neck3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_neck3\", torch.nn.Conv2d(256, 512, kernel_size=3)),\n","            (\"act_neck3\", torch.nn.ReLU(inplace=True))\n","        ]))\n","        self.head = torch.nn.Sequential(collections.OrderedDict([    \n","            (\"reflectpad_head0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_head0\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act_head0\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad_head1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_head1\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act_head1\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad_head2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_head2\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act_head2\", torch.nn.ReLU(inplace=True)),\n","            (\"maxpool_head\", torch.nn.MaxPool2d(2, ceil_mode=True)),\n","            (\"reflectpad_head3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv_head3\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act_head3\", torch.nn.ReLU(inplace=True))\n","        ]))\n","        if pretrained_path is not None:\n","            self.layers.load_state_dict(torch.load(pretrained_path, map_location=lambda storage, loc: storage))\n","\n","        for p in self.parameters():\n","            p.requires_grad = False\n","        \n","        def forward(self, x, target=\"head\", output_last_feature=True):\n","            x_tail = self.tail(x)\n","            x_lower_spine = self.lower_spine(x_tail)\n","            x_spine = self.spine(x_lower_spine)\n","            x_neck = self.neck(x_spine)\n","            x_head = self.head(x_neck)\n","            if output_last_feature:\n","                if target == \"tail\":\n","                    return x_tail\n","                if target == \"lower_spine\":\n","                    return x_lower_spine\n","                if target == \"spine\":\n","                    return x_spine\n","                if target == \"neck\":\n","                    return x_neck\n","                return x_head\n","            else:\n","                if target == \"tail\":\n","                    return x_tail\n","                if target == \"lower_spine\":\n","                    return x_tail, x_lower_spine\n","                if target == \"spine\":\n","                    return x_tail, x_lower_spine, x_spine\n","                if target == \"neck\":\n","                    return x_tail, x_lower_spine, x_spine, x_neck\n","                return x_tail, x_lower_spine, x_spine, x_neck, x_head\n","\n","class Decoder(torch.nn.Module):\n","    def __init__(self, level, pretrained_path=None):\n","        super().__init__()\n","        decoder_layers = collections.OrderedDict([\n","            (\"reflectpad0\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv0\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act0\", torch.nn.ReLU(inplace=True)),\n","            (\"upsample0\", torch.nn.Upsample(scale_factor=2)),\n","            (\"reflectpad1\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv1\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act1\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad2\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv2\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act2\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad3\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv3\", torch.nn.Conv2d(512, 512, kernel_size=3)),\n","            (\"act3\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad4\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv4\", torch.nn.Conv2d(512, 256, kernel_size=3)),\n","            (\"act4\", torch.nn.ReLU(inplace=True)),\n","            (\"upsample1\", torch.nn.Upsample(scale_factor=2)),\n","            (\"reflectpad5\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv5\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act5\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad6\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv6\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act6\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad7\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv7\", torch.nn.Conv2d(256, 256, kernel_size=3)),\n","            (\"act7\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad8\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv8\", torch.nn.Conv2d(256, 128, kernel_size=3)),\n","            (\"act8\", torch.nn.ReLU(inplace=True)),\n","            (\"upsample2\", torch.nn.Upsample(scale_factor=2)),\n","            (\"reflectpad9\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv9\", torch.nn.Conv2d(128, 128, kernel_size=3)),\n","            (\"act9\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad10\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv10\", torch.nn.Conv2d(128, 64, kernel_size=3)),\n","            (\"act10\", torch.nn.ReLU(inplace=True)),\n","            (\"upsample3\", torch.nn.Upsample(scale_factor=2)),\n","            (\"reflectpad11\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv11\", torch.nn.Conv2d(64, 64, kernel_size=3)),\n","            (\"act11\", torch.nn.ReLU(inplace=True)),\n","            (\"reflectpad12\", torch.nn.ReflectionPad2d((1, 1, 1, 1))),\n","            (\"conv12\", torch.nn.Conv2d(64, 3, kernel_size=3))\n","        ])\n","        if level == 1:\n","            self.layers = nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-2:]))\n","        elif level == 2:\n","            self.layers = nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-9:]))\n","        elif level == 3:\n","            self.layers = nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-16:]))\n","        elif level == 4:\n","            self.layers = nn.Sequential(collections.OrderedDict(list(decoder_layers.items())[-29:]))\n","        elif level == 5:\n","            self.layer = nn.Sequential(decoder_layers)\n","        else:\n","            raise ValueError(\"level should be between 1 and 5\")\n","        if pretrained_path is not None:\n","            self.layers.load_state_dict(torch.load(pretrained_path, map_location=lambda storage, loc: storage))\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","class StyleTransferCNN(torch.nn.Module):\n","    def __init__(self, alpha=1, pretrained=False):\n","        super().__init__()\n","        self.alpha = alpha\n","        if pretrained:\n","            torchhub_save_dir = (pathlib.Path.home() / \".cache\" / \"torch\" / \"hub\" / \"checkpoints\")\n","            torchhub_save_dir.mkdir(parents=True, exist_ok=True)\n","            if not (torchhub_save_dir / \"vgg_normalized_conv5_1.pth\").is_file():\n","                download_from_gdrive(\"1IAOFF5rDkVei035228Qp35hcTnliyMol\", \"vgg_normalized_conv5_1.pth\")\n","            if not (torchhub_save_dir / \"decoder_relu4_1.pth\").is_file():\n","                download_from_gdrive(\"1kkoyNwRup9y5GT1mPbsZ_7WPQO9qB7ZZ\", \"decoder_relu4_1.pth\")\n","            self.encoder = NormalizedVGG(pretrained_path=(torchhub_save_dir / \"vgg_normalized_conv5_1.pth\"))\n","            self.decoder = Decoder(level=4, pretrained_path=\"decoder_relu4_1.pth\")\n","        else:\n","            self.encoder = VGGEncoder()\n","            self.decoder = Decoder(level=4)\n","    \n","    def _apply(self, fn):\n","        # redefine to move encoder and decoder to the same device the main model is on\n","        super()._apply(fn)\n","        self.encoder._apply(fn)\n","        self.decoder._apply(fn)\n","        return self\n","\n","    def _calc_k(self, x, max_cluster=5, threshold_min=0.1, threshold_max=0.7):\n","        image = FromTensor()(x)\n","        w, h, = image.size\n","        w, h = self._calc_maxpool_size(w, h)\n","        image = skimage.transform.resize(image, (w, h))\n","        image = skimage.color.rgb2lab(image).reshape(w * h, -1)\n","        k = 2\n","        k_means = KMeans(k, device=x.device)\n","        image = torch.from_numpy(image)\n","        k_means.fit(image)\n","        labels = k_means.labels_\n","        prev_labels = k_means.labels_\n","        prev_cluster_centers = k_means.cluster_centers_\n","        while True:\n","            cnt = collections.Counter(labels.cpu().tolist())\n","            if k <= max_cluster and (cnt.most_common()[-1][1] / (w * h) > threshold_min or cnt.most_common()[0][1] / (w * h) > threshold_max):\n","                if cnt.most_common()[-2][-1] / (w * h) < threshold_min:\n","                    labels = prev_labels\n","                    cluster_centers = prev_cluster_centers\n","                    k -= 1\n","                else:\n","                    labels = k_means.labels_\n","                    cluster_centers = k_means.cluster_centers_\n","                break\n","            \n","            prev_labels = k_means.labels_\n","            prev_cluster_centers = k_means.cluster_centers_\n","\n","            k_means = KMeans(k, device=x.device)\n","            k_means.fit(image)\n","            labels = k_means.labels_\n","        \n","        new_clusters = cluster_centers.norm(dim=1).argsort(descending=False).tolist()\n","        new_clusters = [new_clusters.index(j) for j in range(k)]\n","        cluster_centers_norm, _ = torch.sort(cluster_centers.norm(dim=1))\n","        cluster_centers_norm -= cluster_centers_norm.min()\n","        cluster_centers_norm /= cluster_centers_norm.max()\n","\n","        new_labels = torch.zeros_like(labels)\n","        for i in range(k):\n","            new_labels[labels == i] = new_clusters[i]\n","        \n","        label = new_labels.reshape(h, w)\n","\n","        return label, cluster_centers_norm\n","\n","    def _calc_maxpool_size(self, w, h, count=3):\n","        for _ in range(count):\n","            w = np.ceil(w / 2)\n","            h = np.ceil(h / 2)\n","        return int(w), int(h)\n","\n","    def _cluster_matching(self, content_label, style_label, content_cluster_center_norm, style_cluster_center_norm, threshold=0.25):\n","        content_k = int(content_label.max().item() + 1)\n","        style_k = int(style_label.max().item() + 1)\n","        res = {}\n","        for i in range(content_k):\n","            res[i] = []\n","            match = False\n","            for j in range(style_k):\n","                if torch.abs(content_cluster_center_norm[i] - style_cluster_center_norm[j]) <= threshold:\n","                    match = True\n","                    res[i].append[j]\n","            if not match:\n","                res[i] = [jj for jj in range(style_k)]\n","        \n","        return res\n","\n","    def _labeled_whiten_and_color(self, f_c, f_s, alpha, clabel):\n","        try:\n","            cc, ch, cw = f_c.shape\n","            cf = (f_c * clabel).reshape(cc, -1)\n","            num_nonzero = torch.sum(clabel).item() / cc\n","            c_mean = (torch.sum(cf, 1) / num_nonzero).reshape(cc, 1, 1) * clabel\n","            cf = (cf.reshape(cc, ch, cw) - c_mean).reshape(cc, -1)\n","            \n","            c_cov = torch.mm(cf, ct.t()) / (num_nonzero - 1)\n","            c_u, c_e, c_v = torch.svd(c_cov)\n","            c_d = c_e.pow(-0.5)\n","\n","            w_step1 = torch.mm(c_v, torch.diag(c_d))\n","            w_step2 = torch.mm(w_step1, (c_v.t()))\n","            whitened = torch.mm(w_step2, cf)\n","\n","            sf = f_s\n","            sc, shw = sf.shape\n","            s_mean = torch.mean(f_s, 1, keepdim=True)\n","            sf -= s_mean\n","\n","            s_cov = torch.mm(sf, sf.t()) / (shw - 1)\n","            s_u, s_e, s_v = torch.svd(s_cov)\n","            s_d = s_e.pow(-0.5)\n","\n","            c_step1 = torch.mm(s_v, torch.diag(s_d))\n","            c_step2 = torch.mm(c_step1, s_v.t())\n","            colored = torch.mm(c_step2, whitened).reshape(cc, ch, cw)\n","\n","            colored += s_mean.reshape(sc, 1, 1) * clabel\n","            colored_feature = alpha * colored + (1 - alpha) * (f_c * clabel)\n","        except:\n","            colored_feature = f_c * clabel\n","        \n","        return colored_feature\n","\n","    def generate(self, content, style):\n","        cs = []\n","        content_features = self.encoder(content)\n","        style_features = self.encoder(style)\n","\n","        for c_image, s_image, c_feat, s_feat in zip(content, style, content_features, style_features):\n","            content_label, content_center_norm = self._calc_k(c_image)\n","            style_label, style_center_norm = self._calc_k(s_image)\n","            match = self._cluster_matching(content_label, style_label, content_cluster_center_norm, style_cluster_center_norm)\n","\n","            cs_feature = torch.zeros_like(c_feat)\n","            for i, j in match.items():\n","                cl = (content_label == i).unsqueeze(dim=0).expand_as(c_feat).to(torch.float)\n","                sl = torch.zeros_like(s_feat)\n","                for jj in j:\n","                    sl += (style_label == jj).unsqueeze(dim=0).expand_as(s_feat).to(torch.float)\n","                sl = sl.to(torch.bool)\n","                sub_sf = s_feat[sl].reshape(s_feat.shape[0], -1)\n","                cs_feature += self._labeled_whiten_and_color(c_feat, sub_sf, self.alpha, cl)\n","\n","            cs.append(cs_feature.unsqueeze(dim=0))\n","        cs = torch.cat(cs, dim=0)\n","        out = self.decoder(cs)\n","        return out\n","\n","    def forward(self, content, style):\n","        out = self.generate(content, style)\n","        content_features = self.encoder(content)\n","        out_features = self.encoder(out, output_last_feature=True)\n","        out_middle_features = self.encoder(out, output_last_feature=False)\n","        style_middle_features = self.encoder(style, output_last_feature=False)\n","        return out, content_features, out_features, out_middle_features, style_middle_features"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:10.134206Z","iopub.status.busy":"2022-02-05T23:30:10.133933Z","iopub.status.idle":"2022-02-05T23:30:26.438432Z","shell.execute_reply":"2022-02-05T23:30:26.437699Z","shell.execute_reply.started":"2022-02-05T23:30:10.134163Z"},"id":"8J1UI5t-NtGB","trusted":true},"outputs":[],"source":["model = StyleTransferCNN().to(DEVICE)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:26.439964Z","iopub.status.busy":"2022-02-05T23:30:26.439709Z","iopub.status.idle":"2022-02-05T23:30:31.303014Z","shell.execute_reply":"2022-02-05T23:30:31.302327Z","shell.execute_reply.started":"2022-02-05T23:30:26.439932Z"},"id":"mZw6gccENyqW","outputId":"42707633-95cc-4731-bdd2-8f1fbfd28aee","trusted":true},"outputs":[],"source":["torchinfo.summary(model, ((int(BATCH_SIZE), 3, IMAGE_SIZE, IMAGE_SIZE), (int(BATCH_SIZE), 3, IMAGE_SIZE, IMAGE_SIZE)))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:31.305576Z","iopub.status.busy":"2022-02-05T23:30:31.305113Z","iopub.status.idle":"2022-02-05T23:30:32.063400Z","shell.execute_reply":"2022-02-05T23:30:32.062490Z","shell.execute_reply.started":"2022-02-05T23:30:31.305540Z"},"id":"gqDpk_ZsN_Aj","outputId":"cd70207b-35b3-42f4-8760-7931dfe74db1","trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"Jeab14LGOASp"},"source":["# Defining loss"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:32.065490Z","iopub.status.busy":"2022-02-05T23:30:32.065187Z","iopub.status.idle":"2022-02-05T23:30:33.191455Z","shell.execute_reply":"2022-02-05T23:30:33.190680Z","shell.execute_reply.started":"2022-02-05T23:30:32.065455Z"},"id":"soQqtiY4OBzQ","trusted":true},"outputs":[],"source":["class StyleTransferLoss(torch.nn.Module):\n","    def __init__(self, lam=10):\n","        super().__init__()\n","        self.lam = lam\n","\n","    def _style_loss(self, content_middle, style_middle):\n","        loss = 0\n","        inst_norm = AdaptiveInstanceNorm2d()\n","        for c, s in zip(content_middle, style_middle):\n","            c_mean, c_std = inst_norm._get_mean(c), inst_norm._get_std(c)\n","            s_mean, s_std = inst_norm._get_mean(s), inst_norm._get_std(s)\n","            loss += F.mse_loss(c_mean, s_mean) + F.mse_loss(c_std, s_std)\n","        return loss\n","\n","    def _content_loss(self, output_feats, content_feats):\n","        return F.mse_loss(output_feats, content_feats)\n","\n","    def forward(self, output_feats, content_feats, output_middle, style_middle):\n","        return self._content_loss(output_feats, content_feats) + self.lam * self._style_loss(output_middle, style_middle)"]},{"cell_type":"markdown","metadata":{"id":"SZEn1pE3QHCR"},"source":["# Training model"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:33.195701Z","iopub.status.busy":"2022-02-05T23:30:33.195208Z","iopub.status.idle":"2022-02-05T23:30:33.202635Z","shell.execute_reply":"2022-02-05T23:30:33.201968Z","shell.execute_reply.started":"2022-02-05T23:30:33.195660Z"},"id":"woAUbEidQH5o","trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","criterion = StyleTransferLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-05T23:30:33.205511Z","iopub.status.busy":"2022-02-05T23:30:33.205318Z"},"id":"gvvBnUCbQUhh","outputId":"ba0f6cd5-ea2a-4216-8006-d2449cd5591f","trusted":true},"outputs":[],"source":["max_epochs = 25\n","history_nst = train_model(train_loader, val_loader, model, optimizer, criterion, max_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"elQ-W5hLndcV","outputId":"1aac8b34-d3e8-4c52-e33d-43a3167f889b","trusted":true},"outputs":[],"source":["plot_loss(history_nst)"]},{"cell_type":"markdown","metadata":{"id":"y4aH3RNgnkgF"},"source":["# Validating model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CQsnW7xnpqU","outputId":"116ca5c9-f32a-48d5-8b15-9395a3f7901b","trusted":true},"outputs":[],"source":["test_content, test_style = next(iter(val_loader))\n","test_styled = style_transfer(model, test_content, test_style)\n","plot_pics(Denormalize(mean=NORMALIZATION_PARAMS[\"mean\"], std=NORMALIZATION_PARAMS[\"std\"])(test_styled))"]},{"cell_type":"markdown","metadata":{"id":"AYtSSwoOoXwO"},"source":["# Saving model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TR8PzCjsoYdz","trusted":true},"outputs":[],"source":["save_model(f\"nst_vgg_semst.pth\", model, mode=\"inference\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
